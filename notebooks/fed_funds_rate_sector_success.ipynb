{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.capture_multiple_fred_series import capture_multiple_fred_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # take environment variables from .env.\n",
    "fred_api_key = os.getenv('fred_api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = capture_multiple_fred_series(['FEDFUNDS'],fred_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records for which all values are NaN\n",
    "combined_data.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_etfs = pd.read_csv(os.path.join('data','sector_etfs.csv'),index_col=0,parse_dates=True)\n",
    "sector_etfs = sector_etfs.rename(columns=str.lower)\n",
    "sector_etfs.index = pd.to_datetime(sector_etfs.index)\n",
    "sector_etfs = sector_etfs[['close','volume','ticker']]\n",
    "sector_etfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_index = sector_etfs.copy()\n",
    "min_max_index['index'] = min_max_index.index\n",
    "min_max_index = min_max_index.groupby('ticker')['index'].agg(['min', 'max'])\n",
    "min_max_index.columns = ['min_index', 'max_index']\n",
    "min_max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since XLRE and XLC don't have enough history, I'm going to omit them from this analysis. Perhaps they can be added back in later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_etfs = sector_etfs[~sector_etfs['ticker'].isin(['XLC', 'XLRE'])]\n",
    "sector_etfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlw_estimates = pd.read_csv(os.path.join('data','r_star.csv'),index_col=0,parse_dates=True)\n",
    "# lowercase all columns, and replace spaces, parentheses, commas, and asterisks with underscores\n",
    "hlw_estimates.columns = [col.lower().replace(' ','_').replace('(','').replace(')','').replace(',','').replace('*','') for col in hlw_estimates.columns]\n",
    "hlw_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the hlw_estimates to the combined_data dataframe on the date index\n",
    "combined_data = combined_data.join(hlw_estimates,how='left')\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that have NaN values\n",
    "combined_data.dropna(inplace=True)\n",
    "combined_data['economic_throttle'] = combined_data['fedfunds'] - combined_data['us_natural_rate_r']\n",
    "combined_data.to_csv(os.path.join('data','economic_throttle_data.csv'))\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.plot(y='economic_throttle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_throttle_data = combined_data['economic_throttle']\n",
    "\n",
    "number_of_months = int(((12*2.1)/4))\n",
    "\n",
    "fed_funds_rate_rolling_max = economic_throttle_data.rolling(number_of_months, min_periods=1).max()\n",
    "\n",
    "fed_funds_rate_reversed = economic_throttle_data.iloc[::-1]\n",
    "fed_funds_rate_rolling_max_forward_reversed = fed_funds_rate_reversed.rolling(number_of_months, min_periods=1).max()\n",
    "\n",
    "fed_funds_rate_rolling_max_forward = fed_funds_rate_rolling_max_forward_reversed.iloc[::-1]\n",
    "\n",
    "fed_funds_rate_peaks = economic_throttle_data[(economic_throttle_data == fed_funds_rate_rolling_max) & (economic_throttle_data == fed_funds_rate_rolling_max_forward)]\n",
    "fed_funds_rate_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_funds_rate_peaks = pd.DataFrame(fed_funds_rate_peaks)\n",
    "fed_funds_rate_peaks.columns = ['peaks']\n",
    "fed_funds_rate_peaks['peaks'] = fed_funds_rate_peaks['peaks'].astype('float64')\n",
    "\n",
    "fed_funds_rate_peaks = fed_funds_rate_peaks[fed_funds_rate_peaks['peaks'].notnull()]\n",
    "fed_funds_rate_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pd.Series([False] * len(fed_funds_rate_peaks), index=fed_funds_rate_peaks.index)\n",
    "\n",
    "for i in range(len(fed_funds_rate_peaks)):\n",
    "    if i == 0 or fed_funds_rate_peaks['peaks'].iloc[i] != fed_funds_rate_peaks['peaks'].iloc[i-1]:\n",
    "        mask.iloc[i] = True\n",
    "\n",
    "result_df = fed_funds_rate_peaks[mask]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_etfs.loc[(sector_etfs.index >= '2013-12-29') & (sector_etfs.index <= '2014-01-05')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the sector_etfs and result_df indexes are both datetime objects\n",
    "sector_etfs.index = pd.to_datetime(sector_etfs.index)\n",
    "result_df.index = pd.to_datetime(result_df.index)\n",
    "\n",
    "combined_etf_and_economic_data = sector_etfs.merge(result_df,how='left',left_index=True,right_index=True)\n",
    "combined_etf_and_economic_data.dropna(subset=['peaks'], inplace=True)\n",
    "combined_etf_and_economic_data.reset_index(inplace=True)\n",
    "combined_etf_and_economic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_etfs.reset_index(inplace=True)\n",
    "sector_etfs['timestamp'] = pd.to_datetime(sector_etfs['timestamp'])\n",
    "sector_etfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "economic_data_timestamps = combined_etf_and_economic_data[['timestamp','ticker']].drop_duplicates().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unioned_data = pd.DataFrame()\n",
    "\n",
    "# loop through each combination of timestamp and ticker in the economic_data_timestamps list\n",
    "for timestamp, ticker in economic_data_timestamps:\n",
    "    # convert timestamp to datetime object\n",
    "    timestamp = pd.to_datetime(timestamp)\n",
    "    # create a dataframe of the timestamp and ticker combination saving the next 365 days of ticker data for each respective ticker\n",
    "    sector_etf_data = sector_etfs.loc[(sector_etfs['timestamp'] >= timestamp) & (sector_etfs['timestamp'] <= timestamp + pd.Timedelta(days=(365*2))) & (sector_etfs['ticker'] == ticker)].copy()\n",
    "\n",
    "    sector_etf_data.rename(columns={'timestamp':'future_timestamp','close':'future_close','volume':'future_volume','ticker':'ticker_for_join'},inplace=True)\n",
    "    sector_etf_data['timestamp_for_join'] = timestamp\n",
    "\n",
    "    # add the sector_etf_data dataframe to the unioned_data dataframe without using append\n",
    "    unioned_data = pd.concat([unioned_data,sector_etf_data],axis=0,ignore_index=True)\n",
    "\n",
    "unioned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combined_data = combined_etf_and_economic_data.merge(unioned_data,how='left',left_on=['timestamp','ticker'],right_on=['timestamp_for_join','ticker_for_join'])\n",
    "total_combined_data['cumulative_return'] = total_combined_data['future_close'] / total_combined_data['close'] - 1\n",
    "total_combined_data['rownumber'] = total_combined_data.groupby(['timestamp','ticker']).cumcount() + 1\n",
    "total_combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combined_data.to_csv(os.path.join('data','total_combined_data.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_total_combined_data = total_combined_data.loc[total_combined_data['timestamp'] == pd.to_datetime('2001-01-01')]\n",
    "filtered_total_combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the cumulative_return partitioned by ticker and rownumber\n",
    "averaged_total_combined_data = total_combined_data.groupby(['ticker','rownumber']).agg({'cumulative_return':['mean','count']}).reset_index()\n",
    "\n",
    "# collapse the multi-index columns into a single index by joining the column names with an underscore IF the column is a multi index\n",
    "averaged_total_combined_data.columns = ['_'.join(col) if col[1]!='' else col[0] for col in averaged_total_combined_data.columns.values]\n",
    "\n",
    "averaged_total_combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative_return by rownumber and ticker\n",
    "averaged_total_combined_data.pivot(index='rownumber',columns='ticker',values='cumulative_return_mean').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the averaged_total_combined_data such that each ticker is a column and the cumulative return is the value\n",
    "averaged_total_combined_data_pivoted = averaged_total_combined_data.pivot(index='rownumber',columns='ticker',values='cumulative_return_mean')\n",
    "# rename the rownumber column to \"Days since peak restrictive monetary policy\"\n",
    "averaged_total_combined_data_pivoted.index.name = 'Days since peak restrictive monetary policy'\n",
    "\n",
    "# multiple all values by 100, and round to the second decimal place\n",
    "averaged_total_combined_data_pivoted = averaged_total_combined_data_pivoted * 100\n",
    "averaged_total_combined_data_pivoted = averaged_total_combined_data_pivoted.round(2)\n",
    "\n",
    "# create a dictionary of the tickers and the sector names\n",
    "ticker_sector_dict = {'XLY':'Consumer discretionary','XLP':'Consumer staples','XLE':'Energy','XLF':'Financials','XLV':'Health care','XLI':'Industrials','XLB':'Materials','XLK':'Technology','XLU':'Utilities','SPY':'S&P 500'}\n",
    "\n",
    "# rename the columns of the averaged_total_combined_data_pivoted dataframe using the ticker_sector_dict\n",
    "averaged_total_combined_data_pivoted.columns = [ticker_sector_dict[col] for col in averaged_total_combined_data_pivoted.columns]\n",
    "\n",
    "averaged_total_combined_data_pivoted.to_csv(os.path.join('data','averaged_total_combined_data_pivoted.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
